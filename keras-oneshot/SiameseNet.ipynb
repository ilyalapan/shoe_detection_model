{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy.random as rng\n",
    "import numpy as np\n",
    "from os import *\n",
    "import dill as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imshow\n",
    "from scipy.misc import imread\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "\n",
    "\n",
    "def listdir(path):\n",
    "    l = []\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            l.append(f)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def W_init(shape,name=None):\n",
    "    \"\"\"Initialize weights as in paper\"\"\"\n",
    "    values = rng.normal(loc=0,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "#//TODO: figure out how to initialize layer biases in keras.\n",
    "def b_init(shape,name=None):\n",
    "    \"\"\"Initialize bias as in paper\"\"\"\n",
    "    values=rng.normal(loc=0.5,scale=1e-2,size=shape)\n",
    "    return K.variable(values,name=name)\n",
    "\n",
    "input_shape = (299, 299, 3)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "#build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "convnet.add(Conv2D(64,(10,10),activation='relu',input_shape=input_shape,\n",
    "                   kernel_initializer=W_init,kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(7,7),activation='relu',\n",
    "                   kernel_regularizer=l2(2e-4),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(128,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(Conv2D(256,(4,4),activation='relu',kernel_initializer=W_init,kernel_regularizer=l2(2e-4),bias_initializer=b_init))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(Dense(4096,activation=\"sigmoid\",kernel_regularizer=l2(1e-3),kernel_initializer=W_init,bias_initializer=b_init))\n",
    "#encode each of the two inputs into a vector with the convnet\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "#merge two encoded inputs with the l1 distance between them\n",
    "L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "both = merge([encoded_l,encoded_r], mode = L1_distance, output_shape=lambda x: x[0])\n",
    "prediction = Dense(1,activation='sigmoid',bias_initializer=b_init)(both)\n",
    "siamese_net = Model(input=[left_input,right_input],output=prediction)\n",
    "#optimizer = SGD(0.0004,momentum=0.6,nesterov=True,decay=0.0003)\n",
    "\n",
    "optimizer = Adam(0.00006)\n",
    "#//TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\n",
    "siamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n",
    "\n",
    "siamese_net.count_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''with open( \"/home/soren/keras-oneshot/train.pickle\",\"r\") as f:\n",
    "    (X,c) = pickle.load(f)\n",
    "\n",
    "with open( \"/home/soren/keras-oneshot/val.pickle\",\"r\") as f:\n",
    "    (Xval,cval) = pickle.load(f)\n",
    "#a=siamese_net.predict([X[1,1,:,:].reshape(1,105,105,1),X[7,1,:,:].reshape(1,105,105,1) ])\n",
    "#b=siamese_net.predict([X[7,1,:,:].reshape(1,105,105,1),X[1,1,:,:].reshape(1,105,105,1) ])\n",
    "print(cval)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Siamese_Loader:\n",
    "    \"\"\"For loading batches and testing tasks to a siamese net\"\"\"\n",
    "    #path to data folder\n",
    "    #shape - shape of the images\n",
    "    def __init__(self,path,shape):\n",
    "        self.data = {}\n",
    "        self.categories = {}\n",
    "        self.w,self.h = shape\n",
    "        #self.n_val,self.n_ex_val,_,_ = self.data['val'].shape\n",
    "        self.path = path\n",
    "\n",
    "        \n",
    "    def load_rnd_image(self, category, data_path):\n",
    "        category_path = os.path.join(data_path, category)\n",
    "        idx = rng.randint(len(listdir(category_path)))\n",
    "        example = listdir(category_path)[idx]\n",
    "        example_path = os.path.join(category_path, example)\n",
    "        return imread(example_path,mode = 'RGB')[:,:,:]/255\n",
    "        \n",
    "        \n",
    "    def get_batch(self,n,s=\"train\"):\n",
    "        \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "        data_path = os.path.join(self.path,s)\n",
    "        n_classes = len(listdir(data_path))\n",
    "        #select random categories by name\n",
    "        categories_names = np.array(listdir(data_path))\n",
    "        categories_n = rng.choice(n_classes,size=(n,),replace=False)\n",
    "        categories = categories_names[categories_n]\n",
    "        pairs=[np.zeros((n, self.h, self.w,3), dtype = np.float32) for i in range(2)]\n",
    "        targets=np.zeros((n,))\n",
    "        targets[n//2:] = 1\n",
    "        for i in range(n):\n",
    "            category = categories[i]\n",
    "            category_n = categories_n[i]\n",
    "            pairs[0][i,:,:,:] = self.load_rnd_image(category, data_path)\n",
    "            #pick images of same class for 1st half, different for 2nd\n",
    "            category_2 = category if i >= n//2 else categories_names[(category_n + rng.randint(1,n_classes-1)) % n_classes]\n",
    "            pairs[1][i,:,:,:] = self.load_rnd_image(category_2, data_path)\n",
    "        return pairs, targets\n",
    "    \n",
    "    \n",
    "    def make_oneshot_task(self,N,s='val', verbose = False):\n",
    "        \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "        data_path = os.path.join(self.path,s)\n",
    "        n_classes = len(listdir(data_path))\n",
    "        #get list of category names\n",
    "        categories_names = np.array(listdir(data_path))\n",
    "        #select random numbers for rnadom category selection \n",
    "        categories_n = rng.choice(n_classes,size=(N,),replace=False)\n",
    "        #select random category names\n",
    "        categories = categories_names[categories_n]\n",
    "        true_category = categories[0]\n",
    "        if verbose:\n",
    "            print('True cateogry', ' : ' ,true_category)\n",
    "        test_image = np.asarray([self.load_rnd_image(true_category, data_path)]*N).reshape(N,self.w,self.h,3)\n",
    "        support_set = np.zeros((N, self.w, self.h, 3))\n",
    "        for i in range(1,N):\n",
    "            if verbose:\n",
    "                print(i,' : ',categories[i])\n",
    "            support_set[i,:,:,:] = self.load_rnd_image(categories[i], data_path)\n",
    "        support_set[0,:,:] = self.load_rnd_image(true_category, data_path)\n",
    "        support_set = support_set.reshape(N,self.w,self.h,3)\n",
    "        targets = np.zeros((N,))\n",
    "        targets[0] = 1\n",
    "        targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "        pairs = [test_image,support_set]\n",
    "        return pairs, targets\n",
    "\n",
    "    \n",
    "    def test_oneshot(self,model,N,k,verbose=0):\n",
    "        \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "        pass\n",
    "        n_correct = 0\n",
    "        if verbose:\n",
    "            print(\"Evaluating model on {} unique {} way one-shot learning tasks ...\".format(k,N))\n",
    "        for i in range(k):\n",
    "            inputs, targets = self.make_oneshot_task(N)\n",
    "            probs = model.predict(inputs)\n",
    "            if np.argmax(probs) == 0:\n",
    "                n_correct+=1\n",
    "        percent_correct = (100.0*n_correct / k)\n",
    "        if verbose:\n",
    "            print(\"Got an average of {}% {} way one-shot learning accuracy\".format(percent_correct,N))\n",
    "        return percent_correct\n",
    "    \n",
    "    \n",
    "\n",
    "loader = Siamese_Loader(path = '', shape = (299,299))\n",
    "print('Created the Loader object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "print('Test loading batch of size:' + str(batch_size), flush=True)\n",
    "(inputs, targets) = loader.get_batch(batch_size)\n",
    "print('Batch function working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(inputs)\n",
    "print(targets)\n",
    "i = 20\n",
    "print(inputs[0][i].shape)\n",
    "plt.imshow(inputs[0][i])\n",
    "plt.show()\n",
    "              \n",
    "              \n",
    "print(inputs[1][i].shape)\n",
    "plt.imshow(inputs[1][i])\n",
    "plt.show()\n",
    "              \n",
    "              \n",
    "targets[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(val_inputs, val_targets) = loader.make_oneshot_task(N=3, verbose = True)\n",
    "print(val_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(val_inputs[0][1])\n",
    "plt.show()\n",
    "plt.imshow(val_inputs[1][1])\n",
    "plt.show()\n",
    "\n",
    "val_targets[2]\n",
    "plt.imshow(val_inputs[0][2])\n",
    "plt.show()\n",
    "plt.imshow(val_inputs[1][2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-475e570097d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m#example of a one-shot learning task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_oneshot_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Hebrew\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mplot_oneshot_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-fadf6b957f8c>\u001b[0m in \u001b[0;36mmake_oneshot_task\u001b[0;34m(self, N, s, language)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_oneshot_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;34m\"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'train'"
     ]
    }
   ],
   "source": [
    "\n",
    "def concat_images(X):\n",
    "    \"\"\"Concatenates a bunch of images into a big matrix for plotting purposes.\"\"\"\n",
    "    nc,h,w,_ = X.shape\n",
    "    X = X.reshape(nc,h,w)\n",
    "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
    "    img = np.zeros((n*w,n*h))\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for example in range(nc):\n",
    "        img[x*w:(x+1)*w,y*h:(y+1)*h] = X[example]\n",
    "        y += 1\n",
    "        if y >= n:\n",
    "            y = 0\n",
    "            x += 1\n",
    "    return img\n",
    "\n",
    "\n",
    "def plot_oneshot_task(pairs):\n",
    "    \"\"\"Takes a one-shot task given to a siamese net and  \"\"\"\n",
    "    fig,(ax1,ax2) = plt.subplots(2)\n",
    "    ax1.matshow(pairs[0][0].reshape(105,105),cmap='gray')\n",
    "    img = concat_images(pairs[1])\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.matshow(img,cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "#example of a one-shot learning task\n",
    "pairs, targets = loader.make_oneshot_task(25,\"train\",\"Hebrew\")\n",
    "plot_oneshot_task(pairs)\n",
    "print(targets.reshape(5,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training loop\n",
    "evaluate_every = 500\n",
    "loss_every=50\n",
    "batch_size = 32\n",
    "N_way = 20\n",
    "n_val = 250\n",
    "#siamese_net.load_weights(\"/home/soren/keras-oneshot/weights\")\n",
    "max_epochs = 100\n",
    "for i in range(0,max_epochs):\n",
    "    (inputs,targets)=loader.get_batch(batch_size)\n",
    "    loss=siamese_net.train_on_batch(inputs,targets)\n",
    "    if i % evaluate_every == 0:\n",
    "        val_acc = loader.test_oneshot(siamese_net,N_way,n_val,verbose=True)\n",
    "        if val_acc >= best:\n",
    "            print(\"saving\")\n",
    "            siamese_net.save('/home/soren/keras-oneshot/weights')\n",
    "            best=val_acc\n",
    "\n",
    "    if i % loss_every == 0:\n",
    "        print(\"iteration {}, training loss: {:.2f},\".format(i,loss))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nearest_neighbour(pairs,targets):\n",
    "    L2_distances = np.zeros_like(targets)\n",
    "    for i in range(len(targets)):\n",
    "        L2_distances[i] = np.sum(np.sqrt(pairs[0][i]**2 - pairs[1][i]**2))\n",
    "    if np.argmin(L2_distances) == np.argmax(targets):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def test_nn_accuracy(N_ways,n_trials,loader):\n",
    "    print(\"Evaluating nearest neighbour on {} unique {} way one-shot learning tasks ...\".format(n_trials,N_ways))\n",
    "\n",
    "    n_right = 0\n",
    "    \n",
    "    for i in range(n_trials):\n",
    "        pairs,targets = loader.make_oneshot_task(N_ways,\"val\")\n",
    "        correct = nearest_neighbour(pairs,targets)\n",
    "        n_right+= correct\n",
    "    return 100.0 * n_right / n_trials\n",
    "\n",
    "\n",
    "siamese_net.load_weights(\"/home/soren/keras-oneshot/weights\")\n",
    "ways = np.arange(1,60,2)\n",
    "val_accs, train_accs,nn_accs = [],[],[]\n",
    "print(\"?\")\n",
    "trials = 450\n",
    "for N in ways:\n",
    "    val_accs.append(loader.test_oneshot(siamese_net,N,trials,\"val\",verbose=True))\n",
    "    train_accs.append(loader.test_oneshot(siamese_net,N,trials,\"train\",verbose=True))\n",
    "    nn_accs.append(test_nn_accuracy(N,trials,loader))\n",
    "import seaborn as sns\n",
    "plt.plot(ways,val_accs,\"m\")\n",
    "plt.plot(ways,train_accs,\"y\")\n",
    "plt.plot(ways,nn_accs,\"c\")\n",
    "\n",
    "plt.plot(ways,100.0/ways,\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.plot(ways,val_accs,\"m\",label=\"Siamese(val set)\")\n",
    "ax.plot(ways,train_accs,\"y\",label=\"Siamese(train set)\")\n",
    "plt.plot(ways,nn_accs,label=\"Nearest neighbour\")\n",
    "\n",
    "ax.plot(ways,100.0/ways,\"g\",label=\"Random guessing\")\n",
    "plt.xlabel(\"Number of possible classes in one-shot tasks\")\n",
    "plt.ylabel(\"% Accuracy\")\n",
    "plt.title(\"Omiglot One-Shot Learning Performance of a Siamese Network\")\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "inputs,targets = loader.make_oneshot_task(20,\"val\")\n",
    "plt.show()\n",
    "\n",
    "print(inputs[0].shape)\n",
    "plot_oneshot_task(inputs)\n",
    "p=siamese_net.predict(inputs)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "a=test_nn_accuracy(3,500,loader)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
